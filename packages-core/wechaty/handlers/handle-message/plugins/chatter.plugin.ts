import { SEPARATOR_LINE } from "@cs-magic/common/const"
import { logger } from "@cs-magic/log/logger"
import { ILlmMessage } from "@cs-magic/p01-common/schema/message"
import { types } from "wechaty"
import { z } from "zod"
import { safeCallLLM } from "../../../../../packages-to-classify/llm"

import { formatLlmMessage } from "../../../../../packages-to-classify/llm/utils/format-llm-message"
import { FeatureMap, FeatureType } from "../../../schema/commands"
import { listMessagesOfLatestTopic } from "../../../utils/list-messages-of-latest-topic"
import { BasePlugin } from "./base.plugin"

const commandTypeSchema = z.enum([
  "enable",
  "disable",
  // "new", "list"
])
type CommandType = z.infer<typeof commandTypeSchema>
const i18n: FeatureMap<CommandType> = {
  en: {
    title: "Super Chatter",
    description:
      "Hello, I am the Super Chatter!" +
      "\nThe Only One AI Bot You Need in the WeChat ecosystem." +
      "\nWhat I can help you today? ðŸº",
    commands: {
      enable: {
        type: "enable",
        description: "enable AI chat",
      },
      disable: {
        type: "disable",
        description: "disable AI chat",
      },
      // new: {
      //   type: "new",
      //   description: "create a new topic",
      // },
      // list: {
      //   type: "list",
      //   description: "list all the topics",
      // },
    },
  },
}

export class ChatterPlugin extends BasePlugin {
  static name: FeatureType = "chatter"
  public i18n = i18n

  async help() {
    const commands = await this.getCommands()
    const desc = await this.getDescription()
    const preference = await this.getConvPreference()
    await this.standardReply(
      [
        desc,
        SEPARATOR_LINE,
        "Status:",
        `  - enabled: ${preference.features.chatter.enabled}`,
        `  - model: ${preference.features.chatter.model}`,
      ].join("\n"),
      Object.keys(commands).map(
        (command) => `  ${ChatterPlugin.name} ${command}`,
      ),
    )
  }

  async safeReplyWithAI() {
    const m = this.message
    if (
      // è¿‡æ»¤éžæ–‡æœ¬ todo: image/xxxx
      m.type() !== types.Message.Text ||
      // è¿‡æ»¤è‡ªå·±çš„æ¶ˆæ¯
      m.self() ||
      // è¿‡æ»¤å¾®ä¿¡å®˜æ–¹
      m.talker().id === "weixin" ||
      // è¿‡æ»¤ç¾¤èŠä¸­æ²¡æœ‰atè‡ªå·±çš„æ¶ˆæ¯ ï¼ˆç§ä¿¡è¦å›žï¼‰
      (m.room() &&
        // æ²¡æœ‰è¢« at
        !(
          // including @all
          // await m.mentionSelf()
          // excluding @all
          (await m.mentionList()).some(
            (contact) => contact.id === this.bot.context.wxid,
          )
        ) &&
        // ä¹Ÿæ²¡æœ‰é—®å·å¼€å¤´
        //   todo: å…è®¸å¼€å¤´æœ‰ç©ºæ ¼ï¼Œè¦ä¸ŽåŽç»­æ‰¾ä¿¡æ¯æ—¶å¯¹ä¸Šï¼ˆé‡æž„ä¸€ä¸‹ï¼‰
        !/^\s*[?ï¼Ÿ]/.exec(this.text))
    )
      return

    const convPreference = await this.getConvPreference()
    if (!convPreference.features.chatter.enabled)
      return logger.debug(`!convPreference.features.chatter.enabled`)

    const filteredMessages = await listMessagesOfLatestTopic(
      this.bot.context.wxid,
      this.convId,
    )

    const model = convPreference.features.chatter.model ?? "gpt-3.5-turbo"
    const messages: ILlmMessage[] = filteredMessages.map((m) => ({
      role:
        m.talkerId === this.bot.context.wxid
          ? ("assistant" as const)
          : ("user" as const),
      // todo: merge chats
      content: m.text ?? "",
    }))
    // logger.info(`--  context(len=${context.length})`)

    void this.notify(
      [
        `ðŸŒˆ calling LLM (model=${model})`,
        SEPARATOR_LINE,
        ...messages.map(formatLlmMessage),
      ].join("\n"),
      "chatter",
    )

    const res = await safeCallLLM({
      messages,
      model,
      user: await this.getUserIdentity(),
    })

    if (res.error) throw new Error(res.error)

    const content = res.response?.choices[0]?.message.content
    if (!content)
      throw new Error(
        `invalid response content, please check Query(id=${res.query.id})`,
      )

    void this.bot.context.addSendTask(() => m.say(content))
    void this.notify(
      [`âœ… called LLM`, SEPARATOR_LINE, content].join("\n"),
      "chatter",
    )
  }
}
